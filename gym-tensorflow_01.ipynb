{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import MINST data\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-07 21:40:55,654] Making new env: CartPole-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "n_input = env.observation_space.shape[0]\n",
    "n_actions = int(re.findall('\\d',str(env.action_space))[0])\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "n_steps = 100\n",
    "display_step = 1\n",
    "exploration = 0.1\n",
    "batch_size = 50\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 4 # 1st layer number of features\n",
    "n_hidden_2 = 4 # 2nd layer number of features\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float64, [None, n_input])\n",
    "y = tf.placeholder(tf.float64, [None, n_actions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExperienceQModel(object):\n",
    "    def __init__(self, max_memory=500, discount=.9):\n",
    "        # Memory replay parameters\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "        self.discount = discount\n",
    "\n",
    "    def exp_remember(self, states):\n",
    "        self.memory.append(states.copy())\n",
    "        if len(self.memory) > self.max_memory:\n",
    "          del self.memory[0]\n",
    "\n",
    "    def exp_get_batch(self,batch_size=10):\n",
    "        len_memory = len(self.memory)\n",
    "        n_examples = min(len_memory, batch_size)\n",
    "        inputs = np.zeros((n_examples, n_input))\n",
    "        targets = np.zeros((n_examples, n_actions))\n",
    "        for i, idx in enumerate(np.random.randint(0, len_memory,size=n_examples)):\n",
    "          #get_memory\n",
    "          states = self.memory[idx]\n",
    "          state_t = states['state_t']\n",
    "          state_tp1 = states['state_tp1']\n",
    "\n",
    "          inputs[i] = state_t.astype(np.float64) # assign features\n",
    "\n",
    "          if states['endgame']:\n",
    "            targets[i] = states['reward'] # assign just reward if endgame\n",
    "          else:\n",
    "            feed_dict = {x: states['state_tp1'].reshape(1,-1)}\n",
    "            qvals = sess.run(pred, feed_dict)\n",
    "#             Q_sa = np.max(qvals)\n",
    "            targets[i] = states['reward'] + self.discount * qvals\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Hidden layer with RELU activation\n",
    "#     layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "#     layer_2 = tf.nn.relu(layer_2)\n",
    "    \n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1],dtype=tf.float64)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2],dtype=tf.float64)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_actions],dtype=tf.float64))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1],dtype=tf.float64)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2],dtype=tf.float64)),\n",
    "    'out': tf.Variable(tf.random_normal([n_actions],dtype=tf.float64))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_sum(tf.pow(pred-y, 2))/(2*batch_size)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03653408 -0.0017879   0.02365884 -0.04010206]\n",
      "[-0.03656983 -0.19724099  0.0228568   0.25995057]\n",
      "[-0.04051465 -0.39268165  0.02805581  0.5597543 ]\n",
      "[-0.04836829 -0.58818591  0.0392509   0.86114262]\n",
      "[-0.060132   -0.78381977  0.05647375  1.16590419]\n",
      "[-0.0758084  -0.97962942  0.07979183  1.47574487]\n",
      "[-0.09540099 -1.17563038  0.10930673  1.79224481]\n",
      "[-0.1189136  -1.37179482  0.14515163  2.11680761]\n",
      "[-0.14634949 -1.56803661  0.18748778  2.45059966]\n",
      "Episode finished after 9 timesteps\n",
      "Epoch: 0001 cost= 0.009163758\n",
      "Optimization Finished!\n",
      "[-0.00839862  0.00889034 -0.04087267 -0.0292017 ]\n",
      "[-0.00822081 -0.18562236 -0.0414567   0.25031046]\n",
      "[-0.01193326 -0.38012853 -0.03645049  0.52963425]\n",
      "[-0.01953583 -0.18451327 -0.02585781  0.2256922 ]\n",
      "[-0.0232261  -0.37925631 -0.02134396  0.51010775]\n",
      "[-0.03081122 -0.57407118 -0.01114181  0.79598884]\n",
      "[-0.04229265 -0.76903847  0.00477797  1.085146  ]\n",
      "[-0.05767342 -0.96422312  0.02648089  1.37932436]\n",
      "[-0.07695788 -1.1596655   0.05406738  1.68016962]\n",
      "[-0.10015119 -1.35537069  0.08767077  1.9891865 ]\n",
      "[-0.1272586  -1.55129562  0.1274545   2.30768738]\n",
      "[-0.15828451 -1.74733357  0.17360825  2.63672936]\n",
      "Episode finished after 12 timesteps\n",
      "Epoch: 0002 cost= 0.043000122\n",
      "Optimization Finished!\n",
      "[ 0.02197369  0.04649802  0.04311103  0.01043166]\n",
      "[ 0.02290365 -0.14921483  0.04331966  0.31639889]\n",
      "[ 0.01991935 -0.34492619  0.04964764  0.62242251]\n",
      "[ 0.01302083 -0.54070495  0.06209609  0.93031921]\n",
      "[ 0.00220673 -0.73660756  0.08070247  1.24185129]\n",
      "[-0.01252542 -0.93266737  0.1055395   1.55868461]\n",
      "[-0.03117877 -1.12888268  0.13671319  1.88234096]\n",
      "[-0.05375642 -1.32520302  0.17436001  2.21414236]\n",
      "Episode finished after 8 timesteps\n",
      "Epoch: 0003 cost= 0.047842858\n",
      "Optimization Finished!\n",
      "[ 0.00129503  0.03350663  0.00664108 -0.00699353]\n",
      "[ 0.00196516 -0.16170994  0.00650121  0.28777732]\n",
      "[-0.00126904 -0.35692399  0.01225675  0.58250356]\n",
      "[-0.00840752 -0.5522155   0.02390683  0.87902221]\n",
      "[-0.01945183 -0.74765399  0.04148727  1.17912411]\n",
      "[-0.03440491 -0.94328936  0.06506975  1.48451842]\n",
      "[-0.0532707  -1.13914148  0.09476012  1.79679189]\n",
      "[-0.07605353 -1.33518787  0.13069596  2.11735996]\n",
      "[-0.10275728 -1.53134912  0.17304316  2.44740768]\n",
      "Episode finished after 9 timesteps\n",
      "Epoch: 0004 cost= 0.074259260\n",
      "Optimization Finished!\n",
      "[-0.01994001  0.04341498 -0.02135524 -0.00963826]\n",
      "[-0.01907171  0.23883659 -0.02154801 -0.30898178]\n",
      "[-0.01429498  0.04402818 -0.02772764 -0.02317164]\n",
      "[-0.01341442 -0.15068538 -0.02819107  0.26063556]\n",
      "[-0.01642813 -0.3453938  -0.02297836  0.54429505]\n",
      "[-0.023336   -0.54018544 -0.01209246  0.82965033]\n",
      "[-0.03413971 -0.73514002  0.00450055  1.11850573]\n",
      "[-0.04884251 -0.93032073  0.02687066  1.41259698]\n",
      "[-0.06744893 -1.12576523  0.0551226   1.71355693]\n",
      "[-0.08996423 -0.93131758  0.08939374  1.4385263 ]\n",
      "[-0.10859058 -1.12742015  0.11816426  1.75775238]\n",
      "[-0.13113899 -1.3236661   0.15331931  2.08472809]\n",
      "[-0.15761231 -1.51997002  0.19501387  2.42062938]\n",
      "Episode finished after 13 timesteps\n",
      "Epoch: 0005 cost= 0.132299420\n",
      "Optimization Finished!\n",
      "[-0.0276762  -0.00514647  0.02865294  0.00927315]\n",
      "[-0.02777913 -0.20066738  0.0288384   0.31085694]\n",
      "[-0.03179248 -0.39618807  0.03505554  0.61249335]\n",
      "[-0.03971624 -0.59178195  0.04730541  0.91600813]\n",
      "[-0.05155188 -0.78751058  0.06562557  1.22317525]\n",
      "[-0.06730209 -0.98341363  0.09008907  1.53567734]\n",
      "[-0.08697036 -1.17949749  0.12080262  1.85506074]\n",
      "[-0.11056031 -1.37572202  0.15790384  2.18268213]\n",
      "[-0.13807475 -1.57198512  0.20155748  2.51964528]\n",
      "Episode finished after 9 timesteps\n",
      "Epoch: 0006 cost= 0.106939421\n",
      "Optimization Finished!\n",
      "[ 0.00267469 -0.04196292 -0.03969932 -0.02815537]\n",
      "[ 0.00183544 -0.23649374 -0.04026243  0.2517424 ]\n",
      "[-0.00289444 -0.43101832 -0.03522758  0.53145885]\n",
      "[-0.01151481 -0.62562751 -0.0245984   0.81283676]\n",
      "[-0.02402736 -0.82040406 -0.00834167  1.097682  ]\n",
      "[-0.04043544 -1.0154152   0.01361197  1.3877361 ]\n",
      "[-0.06074374 -1.21070412  0.04136669  1.68464414]\n",
      "[-0.08495782 -1.40627968  0.07505958  1.98991485]\n",
      "[-0.11308342 -1.60210378  0.11485787  2.30487075]\n",
      "[-0.14512549 -1.79807619  0.16095529  2.63058651]\n",
      "Episode finished after 10 timesteps\n",
      "Epoch: 0007 cost= 0.118167167\n",
      "Optimization Finished!\n",
      "[-0.04095335  0.02695999  0.02273754  0.04532537]\n",
      "[-0.04041415 -0.1684805   0.02364405  0.34509459]\n",
      "[-0.04378376 -0.36393068  0.03054594  0.64513861]\n",
      "[-0.05106237 -0.55946468  0.04344872  0.94728191]\n",
      "[-0.06225167 -0.75514393  0.06239435  1.25329367]\n",
      "[-0.07735454 -0.95100711  0.08746023  1.56484879]\n",
      "[-0.09637469 -1.14705886  0.1187572   1.88348292]\n",
      "[-0.11931586 -1.34325642  0.15642686  2.21053905]\n",
      "[-0.14618099 -1.14994205  0.20063764  1.96991014]\n",
      "Episode finished after 9 timesteps\n",
      "Epoch: 0008 cost= 0.105213681\n",
      "Optimization Finished!\n",
      "[-0.01763012 -0.02265552  0.04001141  0.03205902]\n",
      "[-0.01808323 -0.21832774  0.04065259  0.33709265]\n",
      "[-0.02244978 -0.41400391  0.04739444  0.64231297]\n",
      "[-0.03072986 -0.60975333  0.0602407   0.94953614]\n",
      "[-0.04292493 -0.80563222  0.07923142  1.26052158]\n",
      "[-0.05903757 -1.00167317  0.10444186  1.57693015]\n",
      "[-0.07907104 -1.19787315  0.13598046  1.90027656]\n",
      "[-0.1030285  -1.39417976  0.17398599  2.23187345]\n",
      "Episode finished after 8 timesteps\n",
      "Epoch: 0009 cost= 0.092011909\n",
      "Optimization Finished!\n",
      "[ 0.04495859 -0.04813107 -0.04530844 -0.03171796]\n",
      "[ 0.04399597 -0.24257498 -0.0459428   0.24633246]\n",
      "[ 0.03914447 -0.43701168 -0.04101615  0.52417733]\n",
      "[ 0.03040424 -0.63153312 -0.03053261  0.80365872]\n",
      "[ 0.01777357 -0.82622342 -0.01445943  1.08658286]\n",
      "[  1.24910470e-03  -1.02115171e+00   7.27222434e-03   1.37469380e+00]\n",
      "[-0.01917393 -1.21636378  0.0347661   1.66964219]\n",
      "[-0.04350121 -1.41187211  0.06815894  1.97294664]\n",
      "[-0.07173865 -1.60764345  0.10761788  2.28594502]\n",
      "[-0.10389152 -1.80358392  0.15333678  2.609734  ]\n",
      "[-0.13996319 -1.99952131  0.20553146  2.94509622]\n",
      "Episode finished after 11 timesteps\n",
      "Epoch: 0010 cost= 0.127440511\n",
      "Optimization Finished!\n",
      "[-0.03724256 -0.01072111  0.0298004   0.0492729 ]\n",
      "[-0.03745699 -0.20625742  0.03078585  0.35120715]\n",
      "[-0.04158213 -0.01158649  0.03781     0.06838874]\n",
      "[-0.04181386 -0.20722955  0.03917777  0.37275707]\n",
      "[-0.04595845 -0.40288552  0.04663291  0.67753114]\n",
      "[-0.05401617 -0.59862329  0.06018354  0.98452372]\n",
      "[-0.06598863 -0.79449755  0.07987401  1.29548645]\n",
      "[-0.08187858 -0.99053818  0.10578374  1.61206786]\n",
      "[-0.10168935 -1.18673818  0.1380251   1.9357652 ]\n",
      "[-0.12542411 -1.38303967  0.1767404   2.26786775]\n",
      "Episode finished after 10 timesteps\n",
      "Epoch: 0011 cost= 0.113779213\n",
      "Optimization Finished!\n",
      "[ 0.0135268   0.0087651  -0.02802217  0.02186302]\n",
      "[ 0.0137021  -0.18594401 -0.02758491  0.30557458]\n",
      "[ 0.00998322 -0.38066223 -0.02147342  0.58943185]\n",
      "[ 0.00236997 -0.57547702 -0.00968479  0.87527397]\n",
      "[-0.00913957 -0.77046598  0.00782069  1.16489642]\n",
      "[-0.02454889 -0.96568886  0.03111862  1.46002104]\n",
      "[-0.04386266 -1.16117826  0.06031904  1.76226057]\n",
      "[-0.06708623 -1.35692848  0.09556425  2.07307495]\n",
      "[-0.0942248  -1.55288202  0.13702575  2.39371726]\n",
      "[-0.12528244 -1.74891338  0.1849001   2.72516772]\n",
      "Episode finished after 10 timesteps\n",
      "Epoch: 0012 cost= 0.112124953\n",
      "Optimization Finished!\n",
      "[-0.03079928 -0.03420888 -0.0158379   0.03476202]\n",
      "[-0.03148345 -0.22910018 -0.01514266  0.32240615]\n",
      "[-0.03606546 -0.42400326 -0.00869454  0.61027548]\n",
      "[-0.04454552 -0.61900261  0.00351097  0.90020728]\n",
      "[-0.05692557 -0.81417196  0.02151512  1.19399173]\n",
      "[-0.07320901 -1.00956583  0.04539495  1.49333967]\n",
      "[-0.09340033 -1.20520971  0.07526175  1.7998447 ]\n",
      "[-0.11750452 -1.40108829  0.11125864  2.11493688]\n",
      "[-0.14552629 -1.59713136  0.15355738  2.43982594]\n",
      "[-0.17746892 -1.79319717  0.2023539   2.77543271]\n",
      "Episode finished after 10 timesteps\n",
      "Epoch: 0013 cost= 0.109548939\n",
      "Optimization Finished!\n",
      "[-0.04644191  0.03255487  0.04319139  0.04393615]\n",
      "[-0.04579081 -0.16315896  0.04407012  0.34992743]\n",
      "[-0.04905399 -0.35887907  0.05106866  0.65617496]\n",
      "[-0.05623157 -0.55467337  0.06419216  0.96449119]\n",
      "[-0.06732504 -0.75059619  0.08348199  1.27662968]\n",
      "[-0.08233697 -0.9466775   0.10901458  1.59424253]\n",
      "[-0.10127052 -1.14291078  0.14089943  1.91883197]\n",
      "[-0.12412873 -1.33923903  0.17927607  2.25169346]\n",
      "Episode finished after 8 timesteps\n",
      "Epoch: 0014 cost= 0.089529959\n",
      "Optimization Finished!\n",
      "[-0.03020117  0.03695921 -0.01217123  0.04636518]\n",
      "[-0.02946198 -0.15798612 -0.01124392  0.33518326]\n",
      "[-0.03262171 -0.35294626 -0.00454026  0.62429934]\n",
      "[-0.03968063 -0.54800453  0.00794573  0.9155489 ]\n",
      "[-0.05064072 -0.74323303  0.02625671  1.21071843]\n",
      "[-0.06550538 -0.93868396  0.05047107  1.51151236]\n",
      "[-0.08427906 -0.74420838  0.08070132  1.23500265]\n",
      "[-0.09916323 -0.94026951  0.10540138  1.55183763]\n",
      "[-0.11796862 -1.13648581  0.13643813  1.87545936]\n",
      "[-0.14069834 -1.33280779  0.17394732  2.20719411]\n",
      "Episode finished after 10 timesteps\n",
      "Epoch: 0015 cost= 0.110142642\n",
      "Optimization Finished!\n",
      "[ 0.03770832 -0.02951427  0.00283844  0.04325735]\n",
      "[ 0.03711803 -0.22467681  0.00370359  0.33683448]\n",
      "[ 0.0326245  -0.41985127  0.01044028  0.63068301]\n",
      "[ 0.02422747 -0.61511733  0.02305394  0.92663553]\n",
      "[ 0.01192512 -0.81054288  0.04158665  1.22647322]\n",
      "[-0.00428573 -1.0061748   0.06611611  1.53189033]\n",
      "[-0.02440923 -1.20202838  0.09675392  1.84445281]\n",
      "[-0.0484498  -1.39807478  0.13364298  2.16554834]\n",
      "[-0.07641129 -1.59422618  0.17695394  2.49632602]\n",
      "Episode finished after 9 timesteps\n",
      "Epoch: 0016 cost= 0.099261327\n",
      "Optimization Finished!\n",
      "[ 0.01031151 -0.02772268 -0.01888447 -0.02511951]\n",
      "[ 0.00975705 -0.2225688  -0.01938686  0.26154584]\n",
      "[ 0.00530568 -0.41740872 -0.01415595  0.54805142]\n",
      "[-0.0030425  -0.61232897 -0.00319492  0.8362408 ]\n",
      "[-0.01528908 -0.80740713  0.0135299   1.12791725]\n",
      "[-0.03143722 -1.00270369  0.03608824  1.42481294]\n",
      "[-0.05149129 -1.19825267  0.0645845   1.72855306]\n",
      "[-0.07545635 -1.39405047  0.09915556  2.04061209]\n",
      "[-0.10333736 -1.59004246  0.13996781  2.36226003]\n",
      "[-0.13513821 -1.78610689  0.18721301  2.69449686]\n",
      "Episode finished after 10 timesteps\n",
      "Epoch: 0017 cost= 0.111437221\n",
      "Optimization Finished!\n",
      "[ 0.03493841  0.01270139 -0.04808713 -0.01207862]\n",
      "[ 0.03519244 -0.18169912 -0.0483287   0.2650529 ]\n",
      "[ 0.03155846 -0.37609916 -0.04302764  0.54210938]\n",
      "[ 0.02403647 -0.5705908  -0.03218545  0.82093059]\n",
      "[ 0.01262466 -0.76525789 -0.01576684  1.10331911]\n",
      "[-0.0026805  -0.96016894  0.00629954  1.39101408]\n",
      "[-0.02188388 -1.15536877  0.03411982  1.68566008]\n",
      "[-0.04499125 -1.35086846  0.06783302  1.98876821]\n",
      "[-0.07200862 -1.54663289  0.10760839  2.30166716]\n",
      "[-0.10294128 -1.74256575  0.15364173  2.62544233]\n",
      "[-0.1377926  -1.93849172  0.20615058  2.96086253]\n",
      "Episode finished after 11 timesteps\n",
      "Epoch: 0018 cost= 0.119660163\n",
      "Optimization Finished!\n",
      "[ 0.02114256  0.03462695 -0.00274039  0.0428936 ]\n",
      "[ 0.0218351  -0.16045559 -0.00188252  0.33471064]\n",
      "[ 0.01862598 -0.3555507   0.00481169  0.62679933]\n",
      "[ 0.01151497 -0.55073948  0.01734768  0.92099374]\n",
      "[  5.00180838e-04  -7.46091519e-01   3.57675541e-02   1.21907767e+00]\n",
      "[-0.01442165 -0.94165585  0.06014911  1.52274995]\n",
      "[-0.03325477 -1.13745059  0.09060411  1.83358413]\n",
      "[-0.05600378 -1.33345065  0.12727579  2.15297948]\n",
      "[-0.08267279 -1.13978866  0.17033538  1.90215433]\n",
      "[-0.10546856 -1.33629496  0.20837847  2.2424848 ]\n",
      "Episode finished after 10 timesteps\n",
      "Epoch: 0019 cost= 0.108367061\n",
      "Optimization Finished!\n",
      "[ 0.03600289  0.02063728 -0.03933929  0.02170562]\n",
      "[ 0.03641564 -0.17389907 -0.03890518  0.30172161]\n",
      "[ 0.03293766 -0.36844555 -0.03287075  0.58188526]\n",
      "[ 0.02556875 -0.5630919  -0.02123304  0.86403481]\n",
      "[ 0.01430691 -0.75791846 -0.00395235  1.14996674]\n",
      "[ -8.51460846e-04  -9.52988610e-01   1.90469884e-02   1.44140769e+00]\n",
      "[-0.01991123 -1.14833987  0.04787514  1.73998089]\n",
      "[-0.04287803 -1.34397323  0.08267476  2.04716462]\n",
      "[-0.06975749 -1.53984008  0.12361805  2.36424009]\n",
      "[-0.1005543  -1.73582645  0.17090285  2.69222751]\n",
      "Episode finished after 10 timesteps\n",
      "Epoch: 0020 cost= 0.106650658\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "sess = tf.Session()\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)\n",
    "\n",
    "# initialize states and experience replay\n",
    "states = {}\n",
    "exp_replay = ExperienceQModel()\n",
    "env.render()\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    state_tp1 = env.reset()\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        state_t1 = state_tp1\n",
    "        print(state_t1)\n",
    "        \n",
    "        # exploration cycle\n",
    "        if np.random.rand() <= exploration:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            feed_dict = {x: state_t1.reshape(1,-1)}\n",
    "            qvals = sess.run(pred, feed_dict)\n",
    "            action = np.argmax(qvals)\n",
    "\n",
    "        # take a next step\n",
    "        state_tp1, reward, done, info = env.step(action)\n",
    "\n",
    "        # store experience\n",
    "        states['action'] = np.array(action)\n",
    "        states['reward'] = float(reward)\n",
    "        states['endgame'] = done\n",
    "        states['state_t'] = np.array(state_t1)\n",
    "        states['state_tp1'] = np.array(state_tp1)\n",
    "        exp_replay.exp_remember(states)\n",
    "\n",
    "        # get experience replay\n",
    "        x_batch, y_batch = exp_replay.exp_get_batch(batch_size)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: x_batch, y: y_batch})\n",
    "        # Compute average loss\n",
    "        avg_cost += c / n_steps\n",
    "\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost)\n",
    "        \n",
    "    print \"Optimization Finished!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states['state_tp1'].reshape(1,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70402213 -0.98946279]]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {x: states['state_tp1'].reshape(1,-1)}\n",
    "qvals = sess.run(pred, feed_dict)\n",
    "print(qvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8433828 ,  0.17320516],\n",
       "       [ 1.        ,  1.        ],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.82289087,  0.16691397],\n",
       "       [ 1.        ,  1.        ],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.        ,  1.        ],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.        ,  1.        ],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.        ,  1.        ],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.67419238,  0.12126233],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.        ,  1.        ],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.81293395,  0.16385711],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.        ,  1.        ],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.        ,  1.        ],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.8433828 ,  0.17320516],\n",
       "       [ 1.79816952,  0.15932431]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
