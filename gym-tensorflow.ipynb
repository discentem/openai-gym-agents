{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import re\n",
    "import tensorflow as tf\n",
    "\n",
    "class ExperienceQModel(object):\n",
    "    def __init__(self, env='CartPole-v0', max_memory=500, discount=.9, n_episodes=20, \n",
    "                 n_steps=100, n_batch=50, learning_rate = 0.001):\n",
    "        \n",
    "        # Memory replay parameters\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "        self.discount = discount\n",
    "\n",
    "        # environment parameters\n",
    "        self.env = gym.make(env)\n",
    "        self.n_input = self.env.observation_space.shape[0]\n",
    "        self.n_actions = int(re.findall('\\d',str(self.env.action_space))[0])\n",
    "        \n",
    "        # training parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_episodes = n_episodes\n",
    "        self.n_batch = n_batch\n",
    "\n",
    "        # Network Parameters\n",
    "        self.n_hidden_1 = self.n_input/2 # 1st layer number of features\n",
    "        self.n_hidden_2 = 4 # 2nd layer number of features\n",
    "        \n",
    "        # Initialize input and output\n",
    "        self.x = tf.placeholder(\"float\", [None, self.n_input])\n",
    "        self.y = tf.placeholder(\"float\", [None, self.n_actions])\n",
    "        \n",
    "        # Initialize layers weight & bias\n",
    "        self.weights = {\n",
    "            'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "            'out': tf.Variable(tf.random_normal([n_hidden_1, n_actions]))\n",
    "        }\n",
    "        self.biases = {\n",
    "            'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "            'out': tf.Variable(tf.random_normal([n_actions]))\n",
    "        }\n",
    "        \n",
    "\n",
    "    def exp_remember(self, states):\n",
    "        self.memory.append(states.copy())\n",
    "        if len(self.memory) > self.max_memory:\n",
    "          del self.memory[0]\n",
    "\n",
    "    def exp_get_batch(self, model, batch_size=10):\n",
    "        len_memory = len(self.memory)\n",
    "        n_examples = min(len_memory, batch_size)\n",
    "        inputs = np.zeros((n_examples, n_features))\n",
    "        targets = np.zeros((n_examples, n_actions))\n",
    "        for i, idx in enumerate(np.random.randint(0, len_memory,size=n_examples)):\n",
    "          #get_memory\n",
    "          states = self.memory[idx]\n",
    "          state_t = states['state_t'].reshape(1,-1)\n",
    "          state_tp1 = states['state_tp1'].reshape(1,-1)\n",
    "\n",
    "          inputs[i:i+1] = state_t # assign features\n",
    "\n",
    "          if states['endstep']:\n",
    "            targets[i] = states['reward'] # assign reward in the end step\n",
    "          else:\n",
    "            Q_sa = np.max(model.predict(state_tp1)[0])\n",
    "            targets[i] = states['reward'] + self.discount * Q_sa\n",
    "        return inputs, targets\n",
    "\n",
    "    def network_forward(self):\n",
    "        # Hidden layer with RELU activation\n",
    "        layer_1 = tf.add(tf.matmul(self.x, self.weights['h1']), self.biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        \n",
    "        # Output layer with linear activation\n",
    "        out_layer = tf.matmul(layer_1, self.weights['out']) + self.biases['out']\n",
    "    \n",
    "        return out_layer\n",
    "    \n",
    "    def model(self):\n",
    "        # Construct model\n",
    "        pred = self.network_forward()\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, self.y))\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "        # Initializing the variables\n",
    "        init = tf.initialize_all_variables()\n",
    "\n",
    "    # Train loop\n",
    "    def train(self):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "\n",
    "            # Training cycle\n",
    "            for epoch in range(n_episodes):\n",
    "                \n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost)\n",
    "    print \"Optimization Finished!\"\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print \"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels})\n",
    "\n",
    "    for i_episode in range(n_episodes):\n",
    "            observation = env.reset()\n",
    "\n",
    "\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
