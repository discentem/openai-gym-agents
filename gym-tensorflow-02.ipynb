{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExperienceQModel(object):\n",
    "    def __init__(self, env='CartPole-v0', max_memory=10000, discount=.9, n_episodes=100, \n",
    "                 n_steps=100, batch_size=100, learning_rate = 0.01, exploration_a=0.1, exploration_b=0.0):\n",
    "        \n",
    "        # Memory replay parameters\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "        self.discount = discount\n",
    "\n",
    "        # exploration\n",
    "        self.exp_a = exploration_a\n",
    "        self.exp_b = exploration_b # epoch/100 coefficient\n",
    "        \n",
    "        # environment parameters\n",
    "        self.env = gym.make(env)\n",
    "        self.n_input = self.env.observation_space.shape[0]\n",
    "        self.n_actions = int(re.findall('\\d+',str(self.env.action_space))[0]) # shameless hack to get a dim of actions\n",
    "        \n",
    "        # training parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_episodes = n_episodes\n",
    "        self.n_steps = n_steps\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Network Parameters\n",
    "        self.n_hidden_1 = 4 # 1st layer\n",
    "        self.n_hidden_2 = 4\n",
    "        \n",
    "        # Initialize input and output\n",
    "        self.x = tf.placeholder(tf.float64, [None, self.n_input])\n",
    "        self.y = tf.placeholder(tf.float64, [None, self.n_actions])\n",
    "        \n",
    "        # Initialize layers weight & bias\n",
    "        self.weights = {\n",
    "            'h1': tf.Variable(tf.random_normal([self.n_input, self.n_hidden_1],dtype=tf.float64)),\n",
    "            'h2': tf.Variable(tf.random_normal([self.n_hidden_1, self.n_hidden_2],dtype=tf.float64)),\n",
    "            'out': tf.Variable(tf.random_normal([self.n_hidden_2, self.n_actions],dtype=tf.float64))\n",
    "        }\n",
    "        self.biases = {\n",
    "            'b1': tf.Variable(tf.random_normal([self.n_hidden_1],dtype=tf.float64)),\n",
    "            'b2': tf.Variable(tf.random_normal([self.n_hidden_2],dtype=tf.float64)),\n",
    "            'out': tf.Variable(tf.random_normal([self.n_actions],dtype=tf.float64))\n",
    "        }\n",
    "        \n",
    "        # define graph\n",
    "        self.define_model()\n",
    "        \n",
    "\n",
    "    def exp_remember(self, states):\n",
    "        self.memory.append(states.copy())\n",
    "        if len(self.memory) > self.max_memory:\n",
    "          del self.memory[0]\n",
    "\n",
    "    # based on https://gist.github.com/EderSantana/\n",
    "    def exp_get_batch(self):\n",
    "        len_memory = len(self.memory)\n",
    "        n_examples = min(len_memory, self.batch_size)\n",
    "        inputs = np.zeros((n_examples, self.n_input))\n",
    "        targets = np.zeros((n_examples, self.n_actions))\n",
    "        for i, idx in enumerate(np.random.randint(0, len_memory,size=n_examples)):\n",
    "            #get_memory\n",
    "            states = self.memory[idx]\n",
    "            state_t = states['state_t']\n",
    "            state_tp1 = states['state_tp1']\n",
    "            action = states['action']\n",
    "\n",
    "            # input\n",
    "            inputs[i] = state_t.astype(np.float64)\n",
    "\n",
    "            # targets - not correcting those which are not taken\n",
    "            feed_dict = {self.x: states['state_t'].reshape(1,-1)}\n",
    "            targets[i] = self.session.run(self.predictor, feed_dict)\n",
    "            \n",
    "            # acted action\n",
    "            feed_dict = {self.x: states['state_tp1'].reshape(1,-1)}\n",
    "            Qsa = np.max(self.session.run(self.predictor, feed_dict))\n",
    "\n",
    "            # check if endgame and if not apply discount\n",
    "            if states['endgame']:\n",
    "                targets[i,action] = states['reward'] # assign just reward if endgame\n",
    "            else:\n",
    "                targets[i,action] = states['reward'] + self.discount * Qsa\n",
    "        return inputs, targets\n",
    "\n",
    "    # construct network\n",
    "    def network_forward(self):\n",
    "        # Hidden layer with RELU activation\n",
    "        layer_1 = tf.add(tf.matmul(self.x, self.weights['h1']), self.biases['b1'])\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        \n",
    "        layer_2 = tf.add(tf.matmul(layer_1, self.weights['h2']), self.biases['b2'])\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        \n",
    "        # Output layer with linear activation\n",
    "        out_layer = tf.matmul(layer_1, self.weights['out']) + self.biases['out']\n",
    "    \n",
    "        return out_layer\n",
    "    \n",
    "    # Construct model\n",
    "    def define_model(self):\n",
    "        self.predictor = self.network_forward()\n",
    "\n",
    "        # Define loss and optimizer\n",
    "        self.cost = tf.reduce_sum(tf.pow(self.predictor-self.y, 2))/(2*self.batch_size)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "        # Initializing the session\n",
    "        init = tf.initialize_all_variables()\n",
    "        self.session = tf.Session()\n",
    "        self.session.run(init)\n",
    "    \n",
    "    # Train loop\n",
    "    def train_model(self):\n",
    "        # initialize states and experience replay\n",
    "        states = {}\n",
    "        # exp_replay = ExperienceQModel(max_memory=max_memory)\n",
    "\n",
    "        # Training cycle\n",
    "        for epoch in range(self.n_episodes):\n",
    "            avg_cost = 0.\n",
    "            state_tp1 = self.env.reset()\n",
    "            endgame = False\n",
    "\n",
    "            for t in range(self.n_steps):\n",
    "                self.env.render()\n",
    "                state_t1 = np.array(state_tp1)\n",
    "        \n",
    "                # exploration cycle\n",
    "                eps = self.exp_a-self.exp_b*epoch/100\n",
    "                if np.random.rand() <= eps:\n",
    "                    action = self.env.action_space.sample()\n",
    "                else:\n",
    "                    feed_dict = {self.x: state_t1.reshape(1,-1)}\n",
    "                    qvals = self.session.run(self.predictor, feed_dict)\n",
    "                    action = np.argmax(qvals)\n",
    "\n",
    "                # take a next step\n",
    "                state_tp1, reward, endgame, info = self.env.step(action)\n",
    "\n",
    "                # redefine reward\n",
    "                if (t == 99) and (endgame == False):\n",
    "                    print(\"{:4d}: won!\".format(epoch))\n",
    "                if endgame:\n",
    "                    reward = 0;\n",
    "\n",
    "                #store experience\n",
    "                states['action'] = action\n",
    "                states['reward'] = float(reward)\n",
    "                states['endgame'] = endgame\n",
    "                states['state_t'] = np.array(state_t1)\n",
    "                states['state_tp1'] = np.array(state_tp1)\n",
    "                self.exp_remember(states)\n",
    "\n",
    "                # get experience replay\n",
    "                x_batch, y_batch = self.exp_get_batch()\n",
    "                _, c = self.session.run([self.optimizer, self.cost], feed_dict={self.x: x_batch, self.y: y_batch})\n",
    "                # Compute average loss\n",
    "                avg_cost += c / self.n_steps\n",
    "\n",
    "                # Lost\n",
    "                if endgame:\n",
    "                    print(\"{:4d}: lost after {:3d}, cost {:06.4f}\".format(epoch,t+1,avg_cost))\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-08 18:50:07,730] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0: lost after  11, cost 0.0043\n",
      "   1: lost after  10, cost 0.0081\n",
      "   2: lost after  11, cost 0.0175\n",
      "   3: lost after  10, cost 0.0272\n",
      "   4: lost after  10, cost 0.0502\n",
      "   5: lost after   8, cost 0.0557\n",
      "   6: lost after   9, cost 0.0808\n",
      "   7: lost after   9, cost 0.0930\n",
      "   8: lost after  10, cost 0.0925\n",
      "   9: lost after   9, cost 0.0804\n",
      "  10: lost after  10, cost 0.0638\n",
      "  11: lost after   9, cost 0.0433\n",
      "  12: lost after   8, cost 0.0325\n",
      "  13: lost after   9, cost 0.0283\n",
      "  14: lost after  10, cost 0.0258\n",
      "  15: lost after  12, cost 0.0383\n",
      "  16: lost after  10, cost 0.0257\n",
      "  17: lost after  11, cost 0.0273\n",
      "  18: lost after  13, cost 0.0368\n",
      "  19: lost after  11, cost 0.0274\n",
      "  20: lost after  11, cost 0.0292\n",
      "  21: lost after  16, cost 0.0464\n",
      "  22: lost after  13, cost 0.0330\n",
      "  23: lost after  15, cost 0.0380\n",
      "  24: lost after  14, cost 0.1072\n",
      "  25: lost after  19, cost 0.1528\n",
      "  26: lost after  10, cost 0.1276\n",
      "  27: lost after  10, cost 0.1888\n",
      "  28: lost after  25, cost 0.6143\n",
      "  29: lost after  22, cost 0.4697\n",
      "  30: lost after  16, cost 0.3129\n",
      "  31: lost after  28, cost 0.6120\n",
      "  32: lost after  30, cost 0.4982\n",
      "  33: lost after  22, cost 0.3694\n",
      "  34: lost after  22, cost 0.4132\n",
      "  35: lost after  23, cost 0.4533\n",
      "  36: lost after  11, cost 0.1945\n",
      "  37: lost after  23, cost 0.4470\n",
      "  38: lost after  23, cost 0.4134\n",
      "  39: lost after  21, cost 0.3945\n",
      "  40: lost after  19, cost 0.3248\n",
      "  41: lost after  14, cost 0.2294\n",
      "  42: lost after  22, cost 0.4068\n",
      "  43: lost after  14, cost 0.2297\n",
      "  44: lost after   8, cost 0.1563\n",
      "  45: lost after  21, cost 0.3232\n",
      "  46: lost after  14, cost 0.2431\n",
      "  47: lost after  18, cost 0.3060\n",
      "  48: lost after  15, cost 0.2754\n",
      "  49: lost after  34, cost 0.6339\n",
      "  50: lost after  23, cost 0.4190\n",
      "  51: lost after  26, cost 0.4582\n",
      "  52: lost after  15, cost 0.2814\n",
      "  53: lost after  40, cost 0.6978\n",
      "  54: lost after  28, cost 0.4506\n",
      "  55: lost after  20, cost 0.3309\n",
      "  56: lost after  43, cost 0.7606\n",
      "  57: lost after  50, cost 0.7827\n",
      "  58: lost after  45, cost 0.7992\n",
      "  59: lost after  19, cost 0.3021\n",
      "  60: lost after  33, cost 0.4863\n",
      "  61: lost after  22, cost 0.3500\n",
      "  62: lost after  68, cost 1.0057\n",
      "  63: lost after  22, cost 0.3653\n",
      "  64: lost after  39, cost 0.6026\n",
      "  65: lost after  20, cost 0.2914\n",
      "  66: lost after   9, cost 0.1145\n",
      "  67: lost after  12, cost 0.1630\n",
      "  68: lost after  18, cost 0.2461\n",
      "  69: lost after  11, cost 0.1420\n",
      "  70: lost after  10, cost 0.1648\n",
      "  71: lost after  20, cost 0.3161\n",
      "  72: lost after  17, cost 0.2191\n",
      "  73: lost after  27, cost 0.3591\n",
      "  74: lost after  33, cost 0.5347\n",
      "  75: lost after  10, cost 0.1568\n",
      "  76: lost after  36, cost 0.6129\n",
      "  77: lost after  18, cost 0.2674\n",
      "  78: lost after  33, cost 0.5124\n",
      "  79: lost after  39, cost 0.5481\n",
      "  80: lost after   9, cost 0.1418\n",
      "  81: lost after  24, cost 0.3620\n",
      "  82: lost after  15, cost 0.1995\n",
      "  83: lost after   9, cost 0.1470\n",
      "  84: lost after  28, cost 0.3798\n",
      "  85: lost after  32, cost 0.5497\n",
      "  86: lost after  20, cost 0.2521\n",
      "  87: lost after  29, cost 0.3877\n",
      "  88: lost after  37, cost 0.5702\n",
      "  89: lost after  28, cost 0.3557\n",
      "  90: lost after  23, cost 0.2935\n",
      "  91: lost after  19, cost 0.2710\n",
      "  92: lost after  20, cost 0.2916\n",
      "  93: lost after  32, cost 0.4424\n",
      "  94: lost after  46, cost 0.6109\n",
      "  95: lost after  23, cost 0.3653\n",
      "  96: lost after  63, cost 0.8637\n",
      "  97: lost after  55, cost 0.7030\n",
      "  98: lost after  38, cost 0.4775\n",
      "  99: lost after  11, cost 0.1619\n",
      " 100: lost after  10, cost 0.1336\n",
      " 101: lost after  16, cost 0.1841\n",
      " 102: lost after  62, cost 0.6880\n",
      " 103: lost after  17, cost 0.2374\n",
      " 104: lost after  37, cost 0.4817\n",
      " 105: lost after  40, cost 0.5418\n",
      " 106: lost after  39, cost 0.5289\n",
      " 107: lost after  15, cost 0.1701\n",
      " 108: lost after  26, cost 0.3391\n",
      " 109: lost after  32, cost 0.4013\n",
      " 110: lost after  21, cost 0.2708\n",
      " 111: lost after  28, cost 0.3723\n",
      " 112: lost after  19, cost 0.2978\n",
      " 113: lost after  28, cost 0.3718\n",
      " 114: lost after  21, cost 0.2860\n",
      " 115: lost after  28, cost 0.3374\n",
      " 116: lost after  23, cost 0.2926\n",
      " 117: lost after  22, cost 0.2356\n",
      " 118: lost after  28, cost 0.3708\n",
      " 119: lost after  16, cost 0.1690\n",
      " 120: lost after  29, cost 0.3841\n",
      " 121: lost after  26, cost 0.3325\n",
      " 122: lost after  28, cost 0.4037\n",
      " 123: lost after  38, cost 0.4922\n",
      " 124: lost after  32, cost 0.4479\n",
      " 125: lost after  27, cost 0.3148\n",
      " 126: lost after   8, cost 0.0776\n",
      " 127: lost after  31, cost 0.4263\n",
      " 128: lost after  29, cost 0.3772\n",
      " 129: lost after  18, cost 0.2128\n",
      " 130: lost after  21, cost 0.2401\n",
      " 131: lost after  22, cost 0.2649\n",
      " 132: lost after  33, cost 0.3970\n",
      " 133: lost after  22, cost 0.2989\n",
      " 134: lost after  35, cost 0.4425\n",
      " 135: lost after   9, cost 0.1091\n",
      " 136: lost after  38, cost 0.4313\n",
      " 137: lost after  34, cost 0.4650\n",
      " 138: lost after  43, cost 0.4784\n",
      " 139: lost after  32, cost 0.4113\n",
      " 140: lost after  28, cost 0.2711\n",
      " 141: lost after  28, cost 0.3221\n",
      " 142: lost after  44, cost 0.5629\n",
      " 143: lost after  20, cost 0.2443\n",
      " 144: lost after  32, cost 0.3607\n",
      " 145: lost after  32, cost 0.3683\n",
      " 146: lost after  11, cost 0.1309\n",
      " 147: lost after   9, cost 0.0967\n",
      " 148: lost after  35, cost 0.4092\n",
      " 149: lost after  12, cost 0.1150\n",
      " 150: lost after  10, cost 0.0923\n",
      " 151: lost after  22, cost 0.3316\n",
      " 152: lost after  20, cost 0.2307\n",
      " 153: lost after  33, cost 0.4131\n",
      " 154: lost after  28, cost 0.3519\n",
      " 155: lost after  33, cost 0.4097\n",
      " 156: lost after  57, cost 0.7669\n",
      " 157: lost after  67, cost 0.8625\n",
      " 158: lost after  16, cost 0.1971\n",
      " 159: lost after  11, cost 0.1080\n",
      " 160: lost after  37, cost 0.4337\n",
      " 161: lost after  31, cost 0.3910\n",
      " 162: lost after  10, cost 0.1282\n",
      " 163: lost after  22, cost 0.2353\n",
      " 164: lost after  23, cost 0.2132\n",
      " 165: lost after  54, cost 0.6158\n",
      " 166: lost after  10, cost 0.0680\n",
      " 167: lost after  21, cost 0.1849\n",
      " 168: lost after  57, cost 0.4936\n",
      " 169: lost after  69, cost 0.6007\n",
      " 170: lost after  64, cost 0.4816\n",
      " 171: lost after  41, cost 0.3430\n",
      " 172: lost after  48, cost 0.3430\n",
      " 173: lost after  50, cost 0.3690\n",
      " 174: lost after  41, cost 0.3053\n",
      " 175: lost after  47, cost 0.3014\n",
      " 176: lost after  53, cost 0.3470\n",
      " 177: lost after  35, cost 0.2530\n",
      " 178: lost after  78, cost 0.4527\n",
      " 179: lost after  35, cost 0.2042\n",
      " 180: lost after  42, cost 0.2692\n",
      " 181: lost after  52, cost 0.2861\n",
      " 182: lost after  37, cost 0.2010\n",
      " 183: lost after  50, cost 0.2712\n",
      " 184: lost after  49, cost 0.2739\n",
      " 185: lost after  69, cost 0.3458\n",
      " 186: won!\n",
      " 187: won!\n",
      " 188: won!\n",
      " 189: won!\n",
      " 190: won!\n",
      " 191: won!\n",
      " 192: won!\n",
      " 193: won!\n",
      " 194: won!\n",
      " 195: won!\n",
      " 196: won!\n",
      " 197: won!\n",
      " 198: won!\n",
      " 199: won!\n",
      " 200: won!\n",
      " 201: won!\n",
      " 202: won!\n",
      " 203: won!\n",
      " 204: won!\n",
      " 205: won!\n",
      " 206: won!\n",
      " 207: won!\n",
      " 208: won!\n",
      " 209: won!\n",
      " 210: won!\n",
      " 211: won!\n",
      " 212: won!\n",
      " 213: won!\n",
      " 214: won!\n",
      " 215: won!\n",
      " 216: won!\n",
      " 217: won!\n",
      " 218: won!\n",
      " 219: won!\n",
      " 220: won!\n",
      " 221: won!\n",
      " 222: won!\n",
      " 223: won!\n",
      " 224: won!\n",
      " 225: won!\n",
      " 226: won!\n",
      " 227: won!\n",
      " 228: won!\n",
      " 229: won!\n",
      " 230: won!\n",
      " 231: won!\n",
      " 232: won!\n",
      " 233: won!\n",
      " 234: won!\n",
      " 235: won!\n",
      " 236: won!\n",
      " 237: won!\n",
      " 238: won!\n",
      " 239: won!\n",
      " 240: won!\n",
      " 241: won!\n",
      " 242: won!\n",
      " 243: won!\n",
      " 244: won!\n",
      " 245: won!\n",
      " 246: won!\n",
      " 247: won!\n",
      " 248: won!\n",
      " 249: won!\n",
      " 250: won!\n",
      " 251: won!\n",
      " 252: won!\n",
      " 253: won!\n",
      " 254: won!\n",
      " 255: won!\n",
      " 256: won!\n",
      " 257: won!\n",
      " 258: won!\n",
      " 259: won!\n",
      " 260: won!\n",
      " 261: won!\n",
      " 262: won!\n",
      " 263: won!\n",
      " 264: won!\n",
      " 265: won!\n",
      " 266: won!\n",
      " 267: won!\n",
      " 268: won!\n",
      " 269: won!\n",
      " 270: won!\n",
      " 271: won!\n",
      " 272: won!\n",
      " 273: won!\n",
      " 274: won!\n",
      " 275: won!\n",
      " 276: won!\n",
      " 277: won!\n",
      " 278: won!\n",
      " 279: won!\n",
      " 280: won!\n",
      " 281: won!\n",
      " 282: won!\n",
      " 283: won!\n",
      " 284: won!\n",
      " 285: won!\n",
      " 286: won!\n",
      " 287: won!\n",
      " 288: won!\n",
      " 289: won!\n",
      " 290: won!\n",
      " 291: won!\n",
      " 292: won!\n",
      " 293: won!\n",
      " 294: won!\n",
      " 295: won!\n",
      " 296: won!\n",
      " 297: won!\n",
      " 298: won!\n",
      " 299: won!\n",
      " 300: won!\n",
      " 301: won!\n",
      " 302: won!\n",
      " 303: won!\n",
      " 304: won!\n",
      " 305: won!\n",
      " 306: won!\n",
      " 307: won!\n",
      " 308: won!\n",
      " 309: won!\n",
      " 310: won!\n",
      " 311: won!\n",
      " 312: won!\n",
      " 313: won!\n",
      " 314: lost after  53, cost 0.0000\n",
      " 315: won!\n",
      " 316: won!\n",
      " 317: lost after  13, cost 0.0000\n",
      " 318: lost after  40, cost 0.0032\n",
      " 319: lost after   9, cost 0.0000\n",
      " 320: lost after  25, cost 0.0027\n",
      " 321: lost after  14, cost 0.0002\n",
      " 322: lost after   9, cost 0.0001\n",
      " 323: lost after   9, cost 0.0029\n",
      " 324: lost after  10, cost 0.0002\n",
      " 325: lost after   9, cost 0.0004\n",
      " 326: lost after  88, cost 0.0592\n",
      " 327: lost after  94, cost 0.0415\n",
      " 328: won!\n",
      " 329: won!\n",
      " 330: won!\n",
      " 331: won!\n",
      " 332: won!\n",
      " 333: won!\n",
      " 334: won!\n",
      " 335: won!\n",
      " 336: lost after  84, cost 0.0793\n",
      " 337: won!\n",
      " 338: won!\n",
      " 339: won!\n",
      " 340: won!\n",
      " 341: won!\n",
      " 342: won!\n",
      " 343: won!\n",
      " 344: won!\n",
      " 345: lost after  78, cost 0.0635\n",
      " 346: lost after  29, cost 0.0201\n",
      " 347: lost after  25, cost 0.0126\n",
      " 348: won!\n",
      " 349: won!\n",
      " 350: lost after  47, cost 0.0286\n",
      " 351: won!\n",
      " 352: won!\n",
      " 353: won!\n",
      " 354: lost after  12, cost 0.0023\n",
      " 355: won!\n",
      " 356: won!\n",
      " 357: won!\n",
      " 358: won!\n",
      " 359: lost after  40, cost 0.0372\n",
      " 360: won!\n",
      " 361: won!\n",
      " 362: won!\n",
      " 363: won!\n",
      " 364: won!\n",
      " 365: won!\n",
      " 366: lost after  18, cost 0.0148\n",
      " 367: won!\n",
      " 368: won!\n",
      " 369: lost after  15, cost 0.0161\n",
      " 370: won!\n",
      " 371: won!\n",
      " 372: won!\n",
      " 373: won!\n",
      " 374: won!\n",
      " 375: won!\n",
      " 376: won!\n",
      " 377: won!\n",
      " 378: won!\n",
      " 379: won!\n",
      " 380: won!\n",
      " 381: won!\n",
      " 382: won!\n",
      " 383: won!\n",
      " 384: won!\n",
      " 385: won!\n",
      " 386: won!\n",
      " 387: lost after  76, cost 0.0583\n",
      " 388: won!\n",
      " 389: won!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-07-08 19:25:20,060] Observation '[-2.42696043 -3.10960661 -0.0755987   0.61427028]' is not contained within observation space 'Box(4,)'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 390: lost after  97, cost 0.1132\n",
      " 391: won!\n",
      " 392: won!\n",
      " 393: won!\n",
      " 394: won!\n",
      " 395: won!\n",
      " 396: won!\n",
      " 397: won!\n",
      " 398: won!\n",
      " 399: won!\n"
     ]
    }
   ],
   "source": [
    "model = ExperienceQModel(env='CartPole-v0',\\\n",
    "                         max_memory=10000,\\\n",
    "                         discount=.9,\\\n",
    "                         n_episodes=400,\\\n",
    "                         n_steps=100,\\\n",
    "                         batch_size=100,\\\n",
    "                         learning_rate = 1.e-2,\\\n",
    "                         exploration_a = 0.1,\\\n",
    "                         exploration_b = 0.0)\n",
    "model.train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
